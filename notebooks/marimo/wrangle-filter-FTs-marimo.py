import marimo

__generated_with = "0.13.15"
app = marimo.App()


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""## **Collating and Filtering Raw Fusion Calling Output TSV**""")
    return


@app.cell(hide_code=True)
def _():
    import marimo as mo
    return (mo,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""This notebook details the collate-FTs process for the TSV file generated by individual fusion caller and how we combine these information and filter them.""")
    return


@app.cell
def _():
    # load raw tsv
    import polars as pl

    # load_tsv
    arr_pldf = pl.scan_csv('/home/ec2-user/repos/FT-NeonDisco/data/minimal-test/124T_arr.tsv', separator='\t').collect()
    fc_pldf = pl.scan_csv('/home/ec2-user/repos/FT-NeonDisco/data/minimal-test/124T_fc.tsv', separator='\t').fill_null(".").collect()
    sf_pldf = pl.scan_csv('/home/ec2-user/repos/FT-NeonDisco/data/minimal-test/124T_sf.tsv', separator='\t').collect()
    return arr_pldf, fc_pldf, pl, sf_pldf


@app.cell
def _(arr_pldf):
    arr_pldf
    return


@app.cell
def _(sf_pldf):
    sf_pldf
    return


@app.cell
def _(fc_pldf):
    fc_pldf
    return


@app.cell
def _(mo):
    mo.md(
        r"""
    Now we need to define the column structure for the collated file. 

    **Base columns:**

    `fusionTranscriptID    fusionGenePair    breakpointID    5pStrand    3pStrand originalTool    sampleID    sampleNum    sampleNum_Padded`

    **Tool specific columns:**

    Arriba: `5pSite_ARR    3pSite_ARR    mutationType_ARR confidenceLabel_ARR`

    FusionCatcher: `fusionPairAnnotation_FC predictedEffect_FC`

    STARFusion: `largeAnchorSupport_SF junctionReadCount_SF    spanningFragCount_SF    fusionPairAnnotation_SF`
    """
    )
    return


@app.cell
def _(mo):
    mo.md(r"""### Loading Collated TSV for Filtering Steps""")
    return


@app.cell
def _(pl):
    # load collated TSV

    collated_df = pl.scan_csv('/home/ec2-user/repos/FT-NeonDisco/output/minimal-test/collate-RAW-OUT-test.tsv', separator='\t').collect()

    collated_df
    return (collated_df,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""First we filter for unique rows based purely on `['fusionTranscriptID', 'fusionGenePair', 'breakpointID', '5pStrand', '3pStrand']` on the collated TSV. This keeps similar breakpoints that are annotated with paralog gene names. This also retains potentially similar genePair that have different breakpoints.""")
    return


@app.cell
def _(collated_df, pl):
    # Define the columns to group by
    groupby_cols = ['fusionTranscriptID', 'fusionGenePair', 'breakpointID', '5pStrand', '3pStrand']

    # Alternative approach using explicit tool-based logic
    def merge_by_tool_suffixes(df, groupby_cols):
        # Get unique fusions with their tools
        fusion_summary = df.group_by(groupby_cols).agg([
            pl.col("originalTool").unique().alias("detectedBy"),
            pl.col("originalTool").unique().count().alias("toolOverlapCount")
        ])

        result_rows = []

        for fusion_row in fusion_summary.iter_rows(named=True):
            # Start with fusion ID columns
            merged_row = {col: fusion_row[col] for col in groupby_cols}
            tools = fusion_row["detectedBy"]
            tool_count = fusion_row["toolOverlapCount"]
            merged_row["detectedBy"] = " | ".join(tools)
            merged_row["toolOverlapCount"] = tool_count

            # Get data for this fusion
            fusion_filter = pl.all_horizontal([
                pl.col(col) == fusion_row[col] for col in groupby_cols
            ])
            fusion_data = df.filter(fusion_filter)

            # For each column, get data from appropriate tool
            for col in df.columns:
                if col not in groupby_cols and col != "originalTool":
                    # Check if this is a tool-specific column
                    if col.endswith("_ARR") and "Arriba" in tools:
                        # Get Arriba data
                        arriba_data = fusion_data.filter(pl.col("originalTool") == "Arriba")
                        if len(arriba_data) > 0:
                            values = arriba_data.select(col).to_series().to_list()
                            non_null_values = [v for v in values if v is not None and v != "NA"]
                            merged_row[col] = non_null_values[0] if non_null_values else "NA"
                        else:
                            merged_row[col] = "NA"
                    elif col.endswith("_FC") and "FusionCatcher" in tools:
                        # Get FusionCatcher data
                        fc_data = fusion_data.filter(pl.col("originalTool") == "FusionCatcher")
                        if len(fc_data) > 0:
                            values = fc_data.select(col).to_series().to_list()
                            non_null_values = [v for v in values if v is not None and v != "NA"]
                            merged_row[col] = non_null_values[0] if non_null_values else "NA"
                        else:
                            merged_row[col] = "NA"
                    elif col.endswith("_SF") and "STAR-Fusion" in tools:
                        # Get STAR-Fusion data
                        sf_data = fusion_data.filter(pl.col("originalTool") == "STAR-Fusion")
                        if len(sf_data) > 0:
                            values = sf_data.select(col).to_series().to_list()
                            non_null_values = [v for v in values if v is not None and v != "NA"]
                            merged_row[col] = non_null_values[0] if non_null_values else "NA"
                        else:
                            merged_row[col] = "NA"
                    else:
                        # For non-tool-specific columns, take first non-null
                        values = fusion_data.select(col).to_series().to_list()
                        non_null_values = [v for v in values if v is not None and v != "NA"]
                        merged_row[col] = non_null_values[0] if non_null_values else "NA"

            result_rows.append(merged_row)

        return pl.DataFrame(result_rows)

    grouped_df = merge_by_tool_suffixes(collated_df, groupby_cols)

    return (grouped_df,)


@app.cell
def _(grouped_df):
    grouped_df
    return


@app.cell
def _(collated_df):
    # get unique rows based on fusionTranscriptID column and originalTool column

    unique_collated_df = collated_df.unique(subset=["fusionTranscriptID", "originalTool"])

    unique_collated_df # type: ignore

    return (unique_collated_df,)


@app.cell
def _(pl, unique_collated_df):
    # create a new df with unique fusionTranscriptIDs and a list of tools that detected these unique IDs
    tool_group_df = (
        unique_collated_df
        .group_by('fusionTranscriptID')
        .agg(
            pl.col('originalTool').unique().alias('detectedBy'),
            pl.col('originalTool').unique().count().alias('toolOverlapCount')

        )
    )
    return (tool_group_df,)


@app.cell
def _(tool_group_df):
    tool_group_df
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""Now we are ready to use the information in the `tool_group_df` to add the new 'detectedBy' column to the original unique column, by dropping `originalTool` column, running `unique` on `fusionTranscriptID` again, then joining the now truly unique original df with the `tool_group_df` on the `fusionTranscriptID` column.""")
    return


@app.cell
def _(pl, unique_collated_df):
    # unique_fusions_df = (
    #     unique_collated_df
    #     .drop('originalTool')
    #     .unique('fusionTranscriptID')
    #     .join(tool_group_df, on='fusionTranscriptID')
    # )

    unique_fusions_df = (
        unique_collated_df
        .group_by('fusionTranscriptID')
        .agg([
            # Keep all unique values from tool-specific columns
            pl.col('originalTool').unique().alias('detectedBy'),
            pl.col('originalTool').unique().count().alias('toolOverlapCount'),

            # For other columns that might vary by tool, you can:
            # - Take the first value if they should be the same
            pl.col('fusionGenePair').first(),
            pl.col('breakpointID').first(),
            pl.col('5pStrand').first(),
            pl.col('3pStrand').first(),
            pl.col('5pSite').first(),
            pl.col('3pSite').first(),
            pl.col('mutationType').first(),

            # - Or collect all unique values if they might differ
            pl.col('confidenceLabel').unique().alias('confidenceLabels'),
            pl.col('largeAnchorSupport').unique().alias('largeAnchorSupports'),
            pl.col('junctionReadCount').unique().alias('junctionReadCounts'),
            pl.col('spanningFragCount').unique().alias('spanningFragCounts'),
            pl.col('fusionPairAnnotation').unique().alias('fusionPairAnnotations'),

            # Keep sample info
            pl.col('sampleID').first(),
            pl.col('sampleNum').first(),
            pl.col('sampleNum_Padded').first()
        ])
    )

    unique_fusions_df
    return (unique_fusions_df,)


@app.cell
def _(mo):
    mo.md(
        r"""
    ### Load Up CCLE & Internal Cell Line FTs

    We can now load up the parquet file containing the CCLE & Internal Cell Line FT data.
    """
    )
    return


@app.cell
def _(pl):
    # load up CCLE+internal

    ccle_df = pl.scan_parquet('/home/ec2-user/repos/FT-NeonDisco/output/CCLE+internal/01-CCLE+internal-ALL-FT-UNFILTERED.parquet').collect()
    ccle_df
    return (ccle_df,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
    ## Add 'foundInCCLE&InternalCLs' column to unique fusions
    We can now add the `foundInCCLE&InternalCLs` column to the unique fusions dataframe. This will add a new column to the unique fusions dataframe, indicating whether the fusion was found in the CCLE & Internal Cell Lines.

    To achieve this, we will first use the extracted `breakpointID` column from the `ccle_bp_uniq_df` dataframe, and then convert it into a set. This will allow us to check if the `breakpointID` in the unique fusions dataframe is present in the set of `breakpointID`s from the CCLE & Internal Cell Lines dataframe.

    We then will need to create a lambda function that will check if the `breakpointID` in the unique fusions dataframe is present in the set of `breakpointID`s from the CCLE & Internal Cell Lines dataframe. If it is, we will return `True`, otherwise we will return `False`.
    """
    )
    return


@app.cell
def _(ccle_df, pl, unique_fusions_df):

    # create a set of breakpointIDs from the ccle_df dataframe
    ccle_set = set(ccle_df['breakpointID'].to_list())
    # add foundInCCLE&InternalCLs column to unique fusions df by directly checking if the breakpointID is in the set of breakpointIDs from the ccle_df dataframe
    ccle_added_df = unique_fusions_df.with_columns(
        pl.when(pl.col('breakpointID').is_in(ccle_set)).then(True).otherwise(False).alias('foundInCCLE&InternalCLs')
    )

    ccle_added_df
    return (ccle_added_df,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""## Filter Out FTs Found in Panel of Normals (TCGA Normals) Dataset""")
    return


@app.cell
def _(pl):
    # load panel of normals file

    pon_df = pl.scan_csv('/home/ec2-user/repos/FT-NeonDisco/output/TCGANormals/Arr-and-FC_TCGANormals-FTs-with-UNIQUE-breakpointIDs.tsv', separator='\t').collect().drop('detectedBy')

    # save pon_df to parquet
    pon_df.write_parquet('/home/ec2-user/repos/FT-NeonDisco/output/TCGANormals/Arr-and-FC_TCGANormals-FTs-with-UNIQUE-breakpointIDs-v2.parquet')
    # also save to tsv
    pon_df.write_csv('/home/ec2-user/repos/FT-NeonDisco/output/TCGANormals/Arr-and-FC_TCGANormals-FTs-with-UNIQUE-breakpointIDs-v2.tsv', separator='\t')
    # load pon_df from parquet
    pon_pqdf = pl.scan_parquet('/home/ec2-user/repos/FT-NeonDisco/output/TCGANormals/Arr-and-FC_TCGANormals-FTs-with-UNIQUE-breakpointIDs-v2.parquet').collect()
    pon_pqdf
    return (pon_pqdf,)


@app.cell
def _(pon_pqdf):
    set(pon_pqdf['breakpointID'].to_list())
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(r"""Now we can filter out any breakpoints that appear in the PoN dataframe.""")
    return


@app.cell
def _(ccle_added_df, pl, pon_pqdf):
    # create a set of breakpointIDs from the pon_df dataframe
    pon_set = set(pon_pqdf['breakpointID'].to_list())
    # retain only the rows in the ccle_added_df dataframe where the breakpointID is not in the set of breakpointIDs from the pon_df dataframe
    results_df = ccle_added_df.filter(~pl.col('breakpointID').is_in(pon_set))
    results_df
    return (results_df,)


@app.cell
def _(mo):
    mo.md(r"""Finally, we can add a column for FusionInspector, where it contains the same value as 'fusionGenePair' but with the separator :: changed into `--`.""")
    return


@app.cell
def _(pl, results_df):
    # add a column for FusionInspector, where it contains the same value as 'fusionGenePair' but with the separator :: changed into --
    results_df_fusIns = results_df.with_columns(
        pl.col('fusionGenePair').cast(pl.Utf8).str.replace('::', '--').alias('fusionGenePair_FusIns')
    )
    results_df_fusIns


    return (results_df_fusIns,)


@app.cell
def _(pl, results_df_fusIns):
    # we need to represent the nested structure of the detectedBy column as a list of strings
    # Format detectedBy column to use " | " as separator between tools because polars represents the list as nested data
    export_df = results_df_fusIns.with_columns([
        pl.col('detectedBy').list.eval(pl.element().cast(pl.Utf8)).list.join(" | ").alias('detectedBy')
    ])
    export_df
    return (export_df,)


@app.cell
def _(export_df, pl):
    export_filt_df = export_df.filter(pl.col("toolOverlapCount") > 1)
    export_filt_df
    return


@app.cell
def _(export_df, pl):
    # let's grab just the fusionGenePair_FusIns column
    fusins_df = export_df.select(
        pl.col('fusionGenePair_FusIns').unique()
    )
    fusins_df
    fusins_df.write_csv("/home/ec2-user/repos/FT-NeonDisco/output/minimal-test/SAMPLEID_fusins.txt", include_header=False)
    return


if __name__ == "__main__":
    app.run()
